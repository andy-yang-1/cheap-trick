# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def mm(A: T.Buffer[(1152, 1152), "float32"], B: T.Buffer[(1152, 1152), "float32"], Y: T.Buffer[(1152, 1152), "float32"]) -> None:
        # function attr dict
        T.func_attr({"global_symbol": "mm", "tir.noalias": True})
        # body
        # with T.block("root")
        Y_local = T.alloc_buffer([1152, 1152], dtype="float32", scope="local")
        A_shared = T.alloc_buffer([1152, 1152], dtype="float32", scope="shared")
        B_shared = T.alloc_buffer([1152, 1152], dtype="float32", scope="shared")
        A_local = T.alloc_buffer([1152, 1152], dtype="float32", scope="local")
        B_local = T.alloc_buffer([1152, 1152], dtype="float32", scope="local")
        A_shared_local = T.alloc_buffer([1152, 1152], dtype="float32", scope="local")
        B_shared_local = T.alloc_buffer([1152, 1152], dtype="float32", scope="local")
        for i1_0 in T.thread_binding(9, thread="blockIdx.y"):
            for i0_0 in T.thread_binding(36, thread="blockIdx.x"):
                for i1_1 in T.thread_binding(32, thread="threadIdx.y"):
                    for i0_1 in T.thread_binding(2, thread="threadIdx.x"):
                        for i0_2_init, i1_2_init in T.grid(16, 4):
                            with T.block("Y_init"):
                                i = T.axis.spatial(1152, i0_0 * 32 + i0_1 * 16 + i0_2_init)
                                j = T.axis.spatial(1152, i1_0 * 128 + i1_1 * 4 + i1_2_init)
                                T.reads()
                                T.writes(Y_local[i, j])
                                Y_local[i, j] = T.float32(0)
                        for i2_0 in T.serial(288, annotations={"software_pipeline_order":[0, 3, 1, 4, 2], "software_pipeline_stage":[0, 0, 0, 0, 1]}):
                            for ax0_ax1_fused_0 in T.thread_binding(32, thread="threadIdx.y"):
                                for ax0_ax1_fused_1 in T.thread_binding(2, thread="threadIdx.x"):
                                    for ax0_ax1_fused_2 in T.vectorized(2):
                                        with T.block("A_local"):
                                            v0 = T.axis.spatial(1152, i0_0 * 32 + (ax0_ax1_fused_0 * 4 + ax0_ax1_fused_1 * 2 + ax0_ax1_fused_2) // 4)
                                            v1 = T.axis.spatial(1152, i2_0 * 4 + (ax0_ax1_fused_0 * 4 + ax0_ax1_fused_1 * 2 + ax0_ax1_fused_2) % 4)
                                            T.reads(A[v0, v1])
                                            T.writes(A_local[v0, v1])
                                            A_local[v0, v1] = A[v0, v1]
                            for ax0_ax1_fused_0 in T.thread_binding(32, thread="threadIdx.y"):
                                for ax0_ax1_fused_1 in T.thread_binding(2, thread="threadIdx.x"):
                                    for ax0_ax1_fused_2 in T.vectorized(2):
                                        with T.block("A_shared"):
                                            v0 = T.axis.spatial(1152, i0_0 * 32 + (ax0_ax1_fused_0 * 4 + ax0_ax1_fused_1 * 2 + ax0_ax1_fused_2) // 4)
                                            v1 = T.axis.spatial(1152, i2_0 * 4 + (ax0_ax1_fused_0 * 4 + ax0_ax1_fused_1 * 2 + ax0_ax1_fused_2) % 4)
                                            T.reads(A_local[v0, v1])
                                            T.writes(A_shared[v1, v0])
                                            T.block_attr({"double_buffer_scope":0})
                                            A_shared[v1, v0] = A_local[v0, v1]
                            for ax0_ax1_fused_0 in T.thread_binding(32, thread="threadIdx.y"):
                                for ax0_ax1_fused_1 in T.thread_binding(2, thread="threadIdx.x"):
                                    for ax0_ax1_fused_2 in T.vectorized(8):
                                        with T.block("B_local"):
                                            v0 = T.axis.spatial(1152, i2_0 * 4 + (ax0_ax1_fused_0 * 16 + ax0_ax1_fused_1 * 8 + ax0_ax1_fused_2) // 128)
                                            v1 = T.axis.spatial(1152, i1_0 * 128 + (ax0_ax1_fused_0 * 16 + ax0_ax1_fused_1 * 8 + ax0_ax1_fused_2) % 128)
                                            T.reads(B[v0, v1])
                                            T.writes(B_local[v0, v1])
                                            B_local[v0, v1] = B[v0, v1]
                            for ax0_ax1_fused_0 in T.thread_binding(32, thread="threadIdx.y"):
                                for ax0_ax1_fused_1 in T.thread_binding(2, thread="threadIdx.x"):
                                    for ax0_ax1_fused_2 in T.vectorized(8):
                                        with T.block("B_shared"):
                                            v0 = T.axis.spatial(1152, i2_0 * 4 + (ax0_ax1_fused_0 * 16 + ax0_ax1_fused_1 * 8 + ax0_ax1_fused_2) // 128)
                                            v1 = T.axis.spatial(1152, i1_0 * 128 + (ax0_ax1_fused_0 * 16 + ax0_ax1_fused_1 * 8 + ax0_ax1_fused_2) % 128)
                                            T.reads(B_local[v0, v1])
                                            T.writes(B_shared[v0, v1])
                                            T.block_attr({"double_buffer_scope":0})
                                            B_shared[v0, v1] = B_local[v0, v1]
                            for i2_1 in T.unroll(4):
                                for ax0 in T.unroll(16):
                                    for ax1 in T.vectorized(1):
                                        with T.block("A_shared_local"):
                                            v0 = T.axis.spatial(1152, i0_0 * 32 + i0_1 * 16 + ax0)
                                            v1 = T.axis.spatial(1152, i2_0 * 4 + i2_1 + ax1)
                                            T.reads(A_shared[v1, v0])
                                            T.writes(A_shared_local[v0, v1])
                                            A_shared_local[v0, v1] = A_shared[v1, v0]
                                for ax0 in T.unroll(1):
                                    for ax1 in T.vectorized(4):
                                        with T.block("B_shared_local"):
                                            v0 = T.axis.spatial(1152, i2_0 * 4 + i2_1 + ax0)
                                            v1 = T.axis.spatial(1152, i1_0 * 128 + i1_1 * 4 + ax1)
                                            T.reads(B_shared[v0, v1])
                                            T.writes(B_shared_local[v0, v1])
                                            B_shared_local[v0, v1] = B_shared[v0, v1]
                                for i0_2, i1_2 in T.grid(16, 4):
                                    with T.block("Y_update"):
                                        i = T.axis.spatial(1152, i0_0 * 32 + i0_1 * 16 + i0_2)
                                        j = T.axis.spatial(1152, i1_0 * 128 + i1_1 * 4 + i1_2)
                                        k = T.axis.reduce(1152, i2_0 * 4 + i2_1)
                                        T.reads(Y_local[i, j], A_shared_local[i, k], B_shared_local[k, j])
                                        T.writes(Y_local[i, j])
                                        Y_local[i, j] = Y_local[i, j] + A_shared_local[i, k] * B_shared_local[k, j]
                        for ax0 in T.serial(16):
                            for ax1 in T.vectorized(4):
                                with T.block("Y_local"):
                                    v0 = T.axis.spatial(1152, i0_0 * 32 + i0_1 * 16 + ax0)
                                    v1 = T.axis.spatial(1152, i1_0 * 128 + i1_1 * 4 + ax1)
                                    T.reads(Y_local[v0, v1])
                                    T.writes(Y[v0, v1])
                                    Y[v0, v1] = Y_local[v0, v1]
    

